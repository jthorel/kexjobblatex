Automatically generated by Mendeley Desktop 1.15.3
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Preferences -> BibTeX in Mendeley Desktop

@article{Begault2000,
annote = {HRTF

BINAURALT H{\"{O}}RANDE},
author = {Begault, Durand R and Trejo, Leonard J},
file = {:Users/johan/Documents/KTH/kexjobb/källor/3d sound for virtual reality and multimedia.pdf:pdf},
title = {{3-D sound for virtual reality and multimedia}},
year = {2000}
}
@book{Kaplan2005,
author = {Kaplan, Elliott and Hegarty, Christopher},
isbn = {1580538959},
publisher = {Artech house},
title = {{Understanding GPS: principles and applications}},
year = {2005}
}
@article{Walker2006,
abstract = {OBJECTIVE: We examined whether spatialized nonspeech beacons could guide navigation and how sound timbre, waypoint capture radius, and practice affect performance. BACKGROUND: Auditory displays may assist mobility and wayfinding for those with temporary or permanent visual impairment, but they remain understudied. Previous systems have used speech-based interfaces. METHOD: Participants (108 undergraduates) navigated three maps, guided by one of three beacons (pink noise, sonar ping, or 1000-Hz pure tone) spatialized by a virtual reality engine. Dependent measures were efficiency of time and path length. RESULTS: Overall navigation was very successful, with significant effects of practice and capture radius, and interactions with beacon sound. Overshooting and subsequent hunting for waypoints was exacerbated for small radius conditions. A human-scale capture radius (1.5 m) and sonar-like beacon yielded the optimal combination for safety and efficiency. CONCLUSION: The selection of beacon sound and capture radius depend on the specific application, including whether speed of travel or adherence to path are of primary concern. Extended use affects sound preferences and quickly leads to improvements in both speed and accuracy. APPLICATION: These findings should lead to improved wayfinding systems for the visually impaired as well as for first responders (e.g., firefighters) and soldiers.},
annote = {Objective: We examined whether spatialized nonspeech beacons could guide naviga- tion and how sound timbre, waypoint capture radius, and practice affect performance. Background: Auditory displays may assist mobility and wayfinding for those with temporary or permanent visual impairment, but they remain understudied. Previous systems have used speech-based interfaces. Method: Participants (108 undergradu- ates) navigated three maps, guided by one of three beacons (pink noise, sonar ping, or 1000-Hz pure tone) spatialized by a virtual reality engine. Dependent measures were efficiency of time and path length. Results: Overall navigation was very successful, with significant effects of practice and capture radius, and interactions with beacon sound. Overshooting and subsequent hunting for waypoints was exacerbated for small radius conditions. A human-scale capture radius (1.5 m) and sonar-like beacon yielded the optimal combination for safety and efficiency. Conclusion: The selection of beacon sound and capture radius depend on the specific application, including whether speed of travel or adherence to path are of primary concern. Extended use affects sound preferences and quickly leads to improvements in both speed and accu- racy. Application: These findings should lead to improved wayfinding systems for the visually impaired as well as for first responders (e.g., firefighters) and soldiers.},
author = {Walker, Bruce N and Lindsay, Jeffrey},
file = {:Users/johan/Documents/KTH/kexjobb/källor/Navigation Performance With a Virtual Auditory Display.pdf:pdf},
issn = {0018-7208 (Print)},
journal = {Human factors},
keywords = {Adolescent,Adult,Blindness,Female,Georgia,Humans,Locomotion,Male,Sound Localization,Spatial Behavior,Task Performance and Analysis},
language = {eng},
number = {2},
pages = {265--278},
pmid = {16884048},
title = {{Navigation performance with a virtual auditory display: effects of beacon sound, capture radius, and practice.}},
volume = {48},
year = {2006}
}
@inproceedings{Walker2004,
author = {Walker, Bruce N and Lindsay, Jeff},
booktitle = {ICAD},
file = {:Users/johan/Documents/KTH/kexjobb/källor/walker{\_}lindsay.pdf:pdf},
title = {{Auditory Navigation Performance is Affected by Waypoint Capture Radius.}},
year = {2004}
}
@article{Kramer2010,
author = {Kramer, Gregory and Walker, Bruce and Bonebright, Terri and Cook, Perry and Flowers, John H and Miner, Nadine and Neuhoff, John},
file = {:Users/johan/Documents/KTH/kexjobb/källor/fulltext.pdf:pdf},
title = {{Sonification report: Status of the field and research agenda}},
year = {2010}
}
@inproceedings{Sanuki2015,
abstract = {We have developed a mobile navigation system featuring binaural spatial sound delivered via headphones. “Machi-beacon” is intended to promote traffic and pedestrian safety: users select a destination relative to their current position, and the application renders both a visual map and an auditory earcon at the goal. The apparent location of this earcon is adjusted to reflect changes in orientation of the user by modulations of the interaural level difference. To disambiguate front and back directions, the earcon progressively changes between contrasting cues. By desaturating the visual modality, smartphone users can focus on their environment and its hazards and rewards.},
annote = {Navigation med spatialt ljud f{\"{o}}r smartphones. Verkar bara vara en waypoint f{\"{o}}r m{\aa}let endast och visar en karta samtidigt.},
author = {Sanuki, Wataru and Villegas, Juli{\'{a}}n and Cohen, Michael},
booktitle = {Audio Engineering Society Convention 136},
file = {:Users/johan/Documents/KTH/kexjobb/källor/spatial sound mobile navigation.pdf:pdf},
pages = {1--4},
publisher = {Audio Engineering Society},
title = {{Spatial Sound for Mobile Navigation System}},
url = {http://www.aes.org/e-lib/browse.cfm?elib=17141},
year = {2015}
}
@article{Klatzky2006,
author = {Klatzky, Roberta L and Marston, James R and Giudice, Nicholas A and Golledge, Reginald G and Loomis, Jack M},
file = {:Users/johan/Documents/KTH/kexjobb/källor/cognitive load.pdf:pdf},
issn = {1939-2192},
journal = {Journal of Experimental Psychology: Applied},
number = {4},
pages = {223},
publisher = {American Psychological Association},
title = {{Cognitive load of navigating without vision when guided by virtual sound versus spatial language.}},
volume = {12},
year = {2006}
}
@inproceedings{Strachan:2005:GCN:1085777.1085831,
address = {New York, NY, USA},
author = {Strachan, Steven and Eslambolchilar, Parisa and Murray-Smith, Roderick and Hughes, Stephen and O'Modhrain, Sile},
booktitle = {Proceedings of the 7th International Conference on Human Computer Interaction with Mobile Devices {\&}Amp; Services},
doi = {10.1145/1085777.1085831},
file = {:Users/johan/Documents/KTH/kexjobb/källor/gpstunes.pdf:pdf},
isbn = {1-59593-089-2},
keywords = {GPS,audio,hand-held,location-aware,manual control},
pages = {275--278},
publisher = {ACM},
series = {MobileHCI '05},
title = {{GpsTunes: Controlling Navigation via Audio Feedback}},
url = {http://doi.acm.org/10.1145/1085777.1085831},
year = {2005}
}
@article{Holland2002,
abstract = {In this paper we describe a prototype spatial audio user interface for a Global Positioning System (GPS). The interface is designed to allow mobile users to carry out location tasks while their eyes, hands or attention are otherwise engaged. Audio user interfaces for GPS have typically been designed to meet the needs of visually impaired users, and generally, though not exclusively, employ speech-audio. In contrast, our prototype system uses a simple form of non-speech, spatial audio. This paper analyses various candidate audio mappings for location and distance information. A variety of tasks, design considerations, design trade-offs and opportunities are considered. The findings from pilot empirical testing are reported. Finally, opportunities for improvements to the system and for future evaluation are explored.},
address = {London},
annote = {Spatialt ljud f{\"{o}}r navigation.
Testar bara grunderna, riktning och avst{\aa}nd.
Anv{\"{a}}nder sig av eget {\&}quot;Perfekt{\&}quot; ljud.

Slutsats - det r{\"{a}}cker bra.},
author = {Holland, Simon and Morse, David R and Gedenryd, Henrik},
doi = {10.1007/s007790200025},
file = {:Users/johan/Documents/KTH/kexjobb/källor/AudioGPS - Spatial Audio Navigation with a Minimal Attention Interface.pdf:pdf},
issn = {1617-4909},
journal = {Personal and UbiquitousHolland, S., Morse, D. R., {\&} Gedenryd, H. (2002). AudioGPS: Spatial Audio Navigation with a Minimal Attention Interface. Personal and Ubiquitous Computing, 6(4), 253–259. http://doi.org/10.1007/s007790200025 Computing},
keywords = {Key words: Audio – Global Positioning System (GPS)},
number = {4},
pages = {253--259},
title = {{AudioGPS: Spatial Audio Navigation with a Minimal Attention Interface}},
volume = {6},
year = {2002}
}
@article{Loomis1998,
annote = {doi: 10.1162/105474698565677},
author = {Loomis, Jack M and Golledge, Reginald G and Klatzky, Roberta L},
doi = {10.1162/105474698565677},
file = {:Users/johan/Documents/KTH/kexjobb/källor/Navigation System for the Blind.pdf:pdf},
issn = {1054-7460},
journal = {Presence: Teleoperators and Virtual Environments},
month = {apr},
number = {2},
pages = {193--203},
publisher = {MIT Press},
title = {{Navigation System for the Blind: Auditory Display Modes and Guidance}},
url = {http://dx.doi.org/10.1162/105474698565677},
volume = {7},
year = {1998}
}
@article{Nasar2008,
abstract = {Driver distraction is a major cause of traffic accidents, with mobile telephones as a key source of distraction. In two studies, we examined distraction of pedestrians associated with mobile phone use. The first had 60 participants walk along a prescribed route, with half of them conversing on a mobile phone, and the other half holding the phone awaiting a potential call, which never came. Comparison of the performance of the groups in recalling objects planted along the route revealed that pedestrians conversing recalled fewer objects than did those not conversing. The second study had three observers record pedestrian behavior of mobile phone users, i-pod users, and pedestrians with neither one at three crosswalks. Mobile phone users crossed unsafely into oncoming traffic significantly more than did either of the other groups. For pedestrians as with drivers, cognitive distraction from mobile phone use reduces situation awareness, increases unsafe behavior, putting pedestrians at greater risk for accidents, and crime victimization.},
author = {Nasar, Jack and Hecht, Peter and Wener, Richard},
doi = {http://dx.doi.org/10.1016/j.aap.2007.04.005},
issn = {0001-4575},
journal = {Accident Analysis {\&} Prevention},
keywords = {Distraction,Mobile telephones,Pedestrians,Safety,Situation awareness,i-Pod},
month = {jan},
number = {1},
pages = {69--75},
title = {{Mobile telephones, distracted attention, and pedestrian safety}},
url = {http://www.sciencedirect.com/science/article/pii/S000145750700070X},
volume = {40},
year = {2008}
}
@article{Albrecht2016,
abstract = {Music listening and navigation are both common tasks for mobile device users. In this study, we integrated music listening with a navigation service, allowing users to follow the perceived direction of the music to reach their destination. This navigation interface provided users with two different guidance methods: route guidance and beacon guidance. The user experience of the navigation service was evaluated with pedestrians in a city center and with cyclists in a suburban area. The results show that spatialized music can be used to guide pedestrians and cyclists toward a destination without any prior training, offering a pleasant navigation experience. Both route and beacon guidance were deemed good alternatives, but the preference between them varied from person to person and depended on the situation. Beacon guidance was generally considered to be suitable for familiar surroundings, while route guidance was seen as a better alternative for areas that are unfamiliar or more difficult to navigate.},
author = {Albrecht, Robert and V{\"{a}}{\"{a}}n{\"{a}}nen, Riitta and Lokki, Tapio},
doi = {10.1007/s00779-016-0906-z},
file = {:Users/johan/Documents/KTH/kexjobb/källor/guided by music.pdf:pdf},
issn = {1617-4917},
journal = {Personal and Ubiquitous Computing},
number = {1},
pages = {121--145},
title = {{Guided by music: pedestrian and cyclist navigation with route and beacon guidance}},
url = {http://dx.doi.org/10.1007/s00779-016-0906-z},
volume = {20},
year = {2016}
}
@article{Stevens1936,
author = {Stevens, S S and Newman, E B},
doi = {10.2307/1415748},
file = {:Users/johan/Documents/KTH/kexjobb/källor/1936{\_}localization of sound.pdf:pdf},
issn = {00029556},
journal = {The American Journal of Psychology},
number = {2},
pages = {297--306},
publisher = {University of Illinois Press},
title = {{The Localization of Actual Sources of Sound}},
url = {http://www.jstor.org/stable/1415748},
volume = {48},
year = {1936}
}
@article{Jones:2008:ODA:1410427.1410434,
address = {London, UK, UK},
author = {Jones, Matt and Jones, Steve and Bradley, Gareth and Warren, Nigel and Bainbridge, David and Holmes, Geoff},
doi = {10.1007/s00779-007-0155-2},
file = {:Users/johan/Library/Application Support/Mendeley Desktop/Downloaded/Jones et al. - 2008 - ONTRACK Dynamically Adapting Music Playback to Support Navigation.pdf:pdf},
issn = {1617-4909},
journal = {Personal Ubiquitous Comput.},
number = {7},
pages = {513--525},
publisher = {Springer-Verlag},
title = {{ONTRACK: Dynamically Adapting Music Playback to Support Navigation}},
url = {http://dx.doi.org/10.1007/s00779-007-0155-2},
volume = {12},
year = {2008}
}
@misc{Poloj&2282013,
abstract = {In this paper, we present a navigation application, PING!, with a unique combination of characteristics. First, a user can study her/his environment by probing, or sweeping the phone horizontally, upon which points of interest in the pointed directions are indicated with audio feedback. Second, PING! utilizes fuzzy routing. Turn-by-turn instructions are not given and maps are not shown. Instead, the direction of the target is indicated with a simple arrow and binaural audio and the user is free to decide the exact path to take based on this direction information and the environment surrounding her/him. The application, realized in Android devices, was tested in field tests that verified the feasibility of the application concept and revealed directions for further improvement.},
author = {Poloj{\&}{\#}228 and Rvi, Mikko and Saloranta, Timo and Riekki, Jukka},
booktitle = {AcademicMindTrek '13},
doi = {10.1145/2523429.2523479},
editor = {Lugmayr, Artur and Franssila, Helj{\&}{\#}228 and Paavilainen, Janne and K{\&}{\#}228 and Rkk{\&}{\#}228 and Inen, Hannu},
file = {:Users/johan/Documents/KTH/kexjobb/källor/Navigating by audio-based probing and fuzzy routing.pdf:pdf},
keywords = {Audio Interface,Eyes-Free Interface,Fuzzy Routing,Navigation,Non-Visual,Pointing},
pages = {87--94},
publisher = {ACM},
title = {{Navigating by audio-based probing and fuzzy routing}},
year = {2013}
}
@book{Dumas1999,
abstract = {Amazon.com: the book begins by defining usability and explaining methods of usability engineering. Readers are taken through all the steps for planning and conducting a usability test, analysing data, and using the results to improve both products and processes. Included are forms that can be used or modified to conduct a usability test, and layouts of existing labs that will help readers to build their own.},
author = {Dumas, Joseph S and Redish, Janice C},
booktitle = {Star},
isbn = {1841500208},
pages = {404},
title = {{A practical guide to usability testing}},
volume = {Rev. ed.},
year = {1999}
}
@article{Rogers2011,
abstract = {A revision of the 1 text in the Human Computer Interaction field, Interaction Design, the third edition is an ideal resource for learning the interdisciplinary skills needed for interaction design, human-computer interaction, information design, web design and ubiquitous computing. The authors are acknowledged leaders and educators in their field, with a strong global reputation. They bring depth of scope to the subject in this new edition, encompassing the latest technologies and devices including social networking, Web 2.0 and mobile devices. The third edition also adds, develops and updates cases, examples and questions to bring the book in line with the latest in Human Computer Interaction. Interaction Design offers a cross-disciplinary, practical and process-oriented approach to Human Computer Interaction, showing not just what principles ought to apply to Interaction Design, but crucially how they can be applied. The book focuses on how to design interactive products that enhance and extend the way people communicate, interact and work. Motivating examples are included to illustrate both technical, but also social and ethical issues, making the book approachable and adaptable for both Computer Science and non-Computer Science users. Interviews with key HCI luminaries are included and provide an insight into current and future trends.},
author = {Rogers, Yvonne and Sharp, Helen and Preece, Jenny},
journal = {Lecture Notes in Computer Science including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics},
pages = {229,230},
title = {{Interaction Design: Beyond Human-Computer Interaction (3rd ed)}},
url = {http://eu.wiley.com/WileyCDA/WileyTitle/productCd-EHEP001645.html},
volume = {5623 LNCS},
year = {2011}
}
@book{Starch1908,
author = {Starch, D},
publisher = {State University of Iowa.},
title = {{Perimetry of the Localization of Sound ...}},
url = {https://books.google.se/books?id=ClRVAAAAMAAJ},
year = {1908}
}
@misc{Liljedahl2011,
author = {Liljedahl, Mats and Lindberg, Stefan},
doi = {10.1145/2095667.2095668},
file = {:Users/johan/Documents/KTH/kexjobb/källor/Sound Parameters for Expressing Geographic Distance in a Mobile Navigation Application.pdf:pdf},
keywords = {Acoustic Parameters,Auditory Feedback,Geographic Distance,Mobile,Navigation,Sonification,Sound Interaction Design},
pages = {1--7},
title = {{Sound parameters for expressing geographic distance in a mobile navigation application}},
year = {2011}
}
